---
title: 'My Research Review'
date: 2024-12-23
permalink: /posts/2024/12/research-review/
tags:
  - research
---

<!--more-->

# My Research Interests And Statements
NeuroAI, DL&AI, CompCogSci, CompCogNeuro  
**How to Integrate AI and Neuroscience:**  
* Discuss the challenges in current AI and the corresponding solving pathways (or say fileds).  
Flexibility - self-supervised learning, transfer learning, continual learning, meta learning, one-shot learning, imitation learning.  
* Explore potential solutions from neuroscience and the advancements.  
SNN - neuromorphic hardware  
* Envision the prospects of integrating both fileds.

**How to Express:**  
* inductive bias  
* brain  
* human-like

**What are the steps:**

# Research Review For Myself
some papers
## NeuroAI 
### Catalyzing...
* Intro: 
	* Background: CompArch?, DNN-visual processing circuits in the cat neocortex, RL-behavior and neural activity during learning, Attention - [saliency - normalize(or say transform), ...] Decades Old 
	* Challenge: sensorimotor - interact - emobodied, adaptability, flexibility
		> &#10071; The main bottleneck in the development of general robots lies in intelligence rather than hardware. ---_X Square_  
		* engage environments - modular and hierarchy, partial autonomy, amortized control
		* behave flexibly
		* compute efficiently - credit assignment in recurrence for processing sequential information, hardware - [synaptic dynamics within adjacent dendritic spines, spiking]

### OpenBioML
### A dl framework for neuro
* Intro:
	* Classical framework: individual, small sets of, circuit-level neurons -> scale up, thousands of, large neural circuits that perform a multitude of functions like the neocortex or hippocampus
	* ANN: objective function, learning rule - synaptic weight updates, arch - pathways and connections for information flow
	> Many recent findings suggest that deep learning can inform our theories of the brain. First, it has been shown that deep ANNs can, in some cases closely, mimic the representational transformations in primate perceptual systems, and thereby can be leveraged to manipulate neural activity. Second, many well-known behavioral and neurophysiological phenomena, including grid cells, shape tuning, temporal receptive fields, visual illusions, and apparent model-based reasoning, have been shown to emerge in deep ANNs trained on tasks similar to those solved by animals. Third, many modeling studies have demonstrated that the apparent biological implausibility of end-to-end learning rules, e.g. learning algorithms that can mimic the power of the canonical backpropagation-of-error algorithm (backprop) (see Box 1), is overstated. Relatively simple assumptions about cellular and subcellular electrophysiology, inhibitory microcircuits, patterns of spike timing, short term plasticity, and feedback connections can enable biological systems to approximate backprop-like learning in deep ANNs. Hence, ANN-based models of the brain may not be as unrealistic as previously thought, and simultaneously, they appear to explain a lot of neurobiological data.  
	> 
	> Figure 2. Bias and variance in learning rules.
* Constraining: inductive biases

## Extensive AI 
* Challenge: data - large, label - unsupervised, CompResour, Alignment Security
* LLM: pre-train, fine-tune

### Boltzmann Machines
* Energy-based model -> probability distribution, Restricted, Unsupervised learning, Generative learning, Contrastive divergence, Markov random field
* Generative model: VAE, GAN

### CapsuleNet
### Backprop
### Optimization

## Column
### Hinton, Lecun, Hassabis
Extensive AI and NeuroAI

## NeuroAI Prof.
### Blake Richards, McGill
* Research:
	* Credit Assignment: for DL backprop, online learning, modular learning, differentiable-energy.
	* Memory for action and insight
	* Tools

### Konrad Kording, UPenn
* Causal inference

### James Dicarlo, MIT, Daniel Yamins, Stanford, Martin Schimpf, EPFL
* Predictive benchmark

## CompNeuro (physics, statistics)
### Phy: Sukbin Lim, NYUSH
* Neuronal dynamics, Memory models

### Adrienne Fairhall, UW
### Stat: Eero Simoncelli, NYU, Jonathan Pillow, Princeton, Liam Paninski, Columbia, Scott Linderman, Stanford
* Stat

## Cog (psychology, philosophy)
### Songchun Zhu, Peking

## Predictive

## Imaging (large-scale data, biomed)
whole-brain, calcium, optical
### Pengcheng Zhou, CAS
### Medical Imaging: SH

### Continuously Updating...
